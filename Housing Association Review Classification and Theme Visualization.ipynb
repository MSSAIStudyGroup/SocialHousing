{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing Association Review Classification and Theme Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "This Python script processes Housing Association reviews and classifies them based on predefined themes and keywords. The process involves:\n",
    "\n",
    "1. **Loading and Filtering Data:** Reviews with a rating of 1 are filtered from the provided dataset.\n",
    "2. **Loading Themes:** The script loads themes and associated keywords, which represent different classes of social housing issues.\n",
    "3. **Keyword Matching:** Using TF-IDF (Term Frequency-Inverse Document Frequency), the script calculates the cosine similarity between keywords and review content to identify relevant themes in each review.\n",
    "4. **Visualization:** The results are visualized in the form of a heatmap to show the distribution of identified themes (keyword classes) across Housing Associations.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "- **Pandas**: For data manipulation and analysis.\n",
    "- **Scikit-learn**: For vectorizing text data and calculating cosine similarity.\n",
    "- **Matplotlib & Seaborn**: For generating the heatmap visualizations.\n",
    "\n",
    "To run the script, simply replace the file paths for your input data files (`combined_df.csv` for the reviews and `Themes2D.xlsx` for the themes) and execute the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_filter_reviews(file_path):\n",
    "    \"\"\"\n",
    "    Loads Housing Association reviews data from the given CSV file and filters out reviews with RatingValue == 1.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The file path to the reviews data CSV.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with columns: 'HousingAssociation', 'ReviewBody'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Filter reviews with RatingValue == 1\n",
    "    df_filtered = df[df['RatingValue'] == 1][['HousingAssociation', 'ReviewBody']].reset_index(drop=True)\n",
    "    return df_filtered\n",
    "\n",
    "def load_and_process_themes(file_path):\n",
    "    \"\"\"\n",
    "    Loads the themes data from an Excel file and returns a DataFrame with 'Main_Class' and 'Key_words'.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The file path to the themes Excel file.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with columns: 'Main_Class' and 'Key_words'.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df_filtered = df[['Main_Class', 'Key_words']]\n",
    "    return df_filtered\n",
    "\n",
    "def create_keywords_dict(df):\n",
    "    \"\"\"\n",
    "    Converts the 'Key_words' from the themes DataFrame into a dictionary with 'Main_Class' as keys\n",
    "    and lists of keywords as values. Keywords are lowercased and stripped of extra spaces.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing 'Main_Class' and 'Key_words' columns.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are 'Main_Class' and values are lists of keywords.\n",
    "    \"\"\"\n",
    "    keywords_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        class_name = row['Main_Class']\n",
    "        keywords = [keyword.strip().lower() for keyword in row['Key_words'].split(',')]\n",
    "        keywords_dict[class_name] = keywords\n",
    "    return keywords_dict\n",
    "\n",
    "def prepare_keywords_and_classes(keywords_dict):\n",
    "    \"\"\"\n",
    "    Prepares two lists: one with all the keywords and another with their associated classes.\n",
    "    \n",
    "    Parameters:\n",
    "        keywords_dict (dict): A dictionary with 'Main_Class' as keys and lists of keywords as values.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - List of all keywords.\n",
    "            - List of corresponding classes for each keyword.\n",
    "    \"\"\"\n",
    "    keywords_list = []\n",
    "    keyword_classes = []\n",
    "    for class_name, keywords in keywords_dict.items():\n",
    "        for keyword in keywords:\n",
    "            keywords_list.append(keyword)\n",
    "            keyword_classes.append(class_name)\n",
    "    return keywords_list, keyword_classes\n",
    "\n",
    "def vectorize_texts(keywords_list, reviews_list):\n",
    "    \"\"\"\n",
    "    Vectorizes the given list of keywords and reviews using TF-IDF.\n",
    "    \n",
    "    Parameters:\n",
    "        keywords_list (list): List of keywords.\n",
    "        reviews_list (list): List of reviews (strings).\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - TF-IDF matrix for reviews.\n",
    "            - TF-IDF matrix for keywords.\n",
    "            - The vectorizer used for transforming the texts.\n",
    "    \"\"\"\n",
    "    all_texts = keywords_list + reviews_list  # Combine keywords and reviews for TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # Split the matrix into keywords and reviews parts\n",
    "    keywords_tfidf = tfidf_matrix[:len(keywords_list)]  # First part for keywords\n",
    "    reviews_tfidf = tfidf_matrix[len(keywords_list):]  # Remaining part for reviews\n",
    "    return reviews_tfidf, keywords_tfidf, vectorizer\n",
    "\n",
    "def calculate_cosine_similarity(reviews_tfidf, keywords_tfidf):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between reviews and keywords.\n",
    "    \n",
    "    Parameters:\n",
    "        reviews_tfidf (scipy.sparse.csr_matrix): TF-IDF matrix for reviews.\n",
    "        keywords_tfidf (scipy.sparse.csr_matrix): TF-IDF matrix for keywords.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Cosine similarity scores between reviews and keywords.\n",
    "    \"\"\"\n",
    "    return cosine_similarity(reviews_tfidf, keywords_tfidf)\n",
    "\n",
    "def match_keywords_to_reviews(similarity_scores, keyword_classes, df_reviews, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Matches keywords to reviews based on cosine similarity and counts the occurrences of each keyword class in each review.\n",
    "    \n",
    "    Parameters:\n",
    "        similarity_scores (numpy.ndarray): Matrix of cosine similarity scores between reviews and keywords.\n",
    "        keyword_classes (list): List of classes corresponding to the keywords.\n",
    "        df_reviews (pd.DataFrame): DataFrame containing the review data.\n",
    "        threshold (float): Cosine similarity threshold for considering a match.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries with 'HousingAssociation', 'Class', and 'Count' for each matched class.\n",
    "    \"\"\"\n",
    "    keyword_counts = []\n",
    "    for review_idx, row in df_reviews.iterrows():\n",
    "        ha_name = row['HousingAssociation']\n",
    "        matches = {}\n",
    "        \n",
    "        # Iterate through each similarity score for the current review\n",
    "        for keyword_idx, score in enumerate(similarity_scores[review_idx]):\n",
    "            if score > threshold:  # Only count matches above the threshold\n",
    "                class_name = keyword_classes[keyword_idx]\n",
    "                matches[class_name] = matches.get(class_name, 0) + 1\n",
    "        \n",
    "        # Append the matched counts to the result list\n",
    "        for class_name, count in matches.items():\n",
    "            keyword_counts.append({'HousingAssociation': ha_name, 'Class': class_name, 'Count': count})\n",
    "    \n",
    "    return keyword_counts\n",
    "\n",
    "def visualize_keyword_distribution(keyword_df):\n",
    "    \"\"\"\n",
    "    Visualizes the keyword distribution using a heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "        keyword_df (pd.DataFrame): DataFrame containing the keyword count distribution.\n",
    "    \"\"\"\n",
    "    # Create a pivot table for the heatmap\n",
    "    distribution = keyword_df.pivot_table(index='HousingAssociation', columns='Class', values='Count', aggfunc='sum', fill_value=0)\n",
    "    \n",
    "    # Plotting the heatmap\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    sns.heatmap(distribution, annot=True, cmap='YlGnBu', cbar=True)\n",
    "    plt.title(\"Keyword Distribution for Housing Association Reviews\")\n",
    "    plt.xlabel(\"Social Housing Issues (Classes)\")\n",
    "    plt.ylabel(\"Housing Association\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the entire process of analyzing Housing Association reviews,\n",
    "    matching keywords based on similarity, and visualizing the results.\n",
    "    \"\"\"\n",
    "    # File paths (replace 'YOURpath' with actual paths)\n",
    "    reviews_file_path = \"YOURpath/combined_df.csv\"\n",
    "    themes_file_path = \"YOURpath/Themes2D.xlsx\" \n",
    "    \n",
    "    # Step 1: Load and filter reviews data\n",
    "    df_reviews = load_and_filter_reviews(reviews_file_path)\n",
    "    \n",
    "    # Step 2: Load and process themes data\n",
    "    df_themes = load_and_process_themes(themes_file_path)\n",
    "    \n",
    "    # Step 3: Create a dictionary of keywords grouped by class\n",
    "    keywords_dict = create_keywords_dict(df_themes)\n",
    "    \n",
    "    # Step 4: Prepare lists of keywords and their corresponding classes\n",
    "    keywords_list, keyword_classes = prepare_keywords_and_classes(keywords_dict)\n",
    "    \n",
    "    # Step 5: Vectorize the reviews and keywords using TF-IDF\n",
    "    reviews_tfidf, keywords_tfidf, vectorizer = vectorize_texts(keywords_list, df_reviews['ReviewBody'].tolist())\n",
    "    \n",
    "    # Step 6: Calculate cosine similarity between reviews and keywords\n",
    "    similarity_scores = calculate_cosine_similarity(reviews_tfidf, keywords_tfidf)\n",
    "    \n",
    "    # Step 7: Match keywords to reviews and count occurrences by class\n",
    "    keyword_counts = match_keywords_to_reviews(similarity_scores, keyword_classes, df_reviews)\n",
    "    \n",
    "    # Step 8: Convert the counts into a DataFrame\n",
    "    keyword_df = pd.DataFrame(keyword_counts)\n",
    "    \n",
    "    # Step 9: Check if the DataFrame is empty, else proceed with visualization\n",
    "    if keyword_df.empty:\n",
    "        print(\"No keywords found in any review.\")\n",
    "    else:\n",
    "        print(\"Keyword Distribution for Housing Association:\")\n",
    "        distribution = keyword_df.pivot_table(index='HousingAssociation', columns='Class', values='Count', aggfunc='sum', fill_value=0)\n",
    "        print(distribution)\n",
    "        visualize_keyword_distribution(keyword_df)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
