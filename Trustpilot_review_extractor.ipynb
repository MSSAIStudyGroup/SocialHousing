{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trustpilot_review_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Trustpilot Review Extraction Script\n",
    "\n",
    "This script extracts Trustpilot review data for a given company or Housing Association.\n",
    "It fetches the review details from the provided URL, processes the raw HTML data, and \n",
    "returns a structured Pandas DataFrame containing the following review information:\n",
    "- User names\n",
    "- User URLs\n",
    "- Review publication dates\n",
    "- Review bodies\n",
    "- Rating values\n",
    "- Housing association or company name\n",
    "- Source URL of the review\n",
    "\n",
    "The script works with URLs in various formats, including those with or without \n",
    "the 'page' parameter, and it automatically processes the relevant data.\n",
    "\n",
    "How to use:\n",
    "1. Set the base URL for the Trustpilot page you want to extract reviews from.\n",
    "   Example: \n",
    "     URL = 'https://uk.trustpilot.com/review/placesforpeople.co.uk'\n",
    "\n",
    "2. Run the script. It will automatically fetch the review data, extract relevant information, \n",
    "   and return it in a Pandas DataFrame.\n",
    "\n",
    "3. You can print the DataFrame or save it to a CSV file for further analysis.\n",
    "\n",
    "Requirements:\n",
    "- `requests`\n",
    "- `beautifulsoup4`\n",
    "- `pandas`\n",
    "\n",
    "To install the required libraries, you can use:\n",
    "  pip install requests beautifulsoup4 pandas\n",
    "\n",
    "Example:\n",
    "- Simply run the script and view the output:\n",
    "  reviews_df = scraper.get_reviews()\n",
    "  print(reviews_df)\n",
    "\n",
    "This script can be adapted for other Trustpilot URLs as well by modifying the base URL.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from html.parser import HTMLParser\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class TrustpilotReviewScraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.soup = None\n",
    "        self.raw_data = None\n",
    "        self.reviews_data = None\n",
    "\n",
    "    class MyHTMLParser(HTMLParser):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.data = []\n",
    "\n",
    "        def handle_data(self, data):\n",
    "            self.data.append(data)\n",
    "\n",
    "    def fetch_page(self):\n",
    "        response = requests.get(self.url)\n",
    "        if response.status_code == 200:\n",
    "            self.soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        else:\n",
    "            raise Exception(f\"Failed to fetch the page: {response.status_code}\")\n",
    "\n",
    "    def parse_script_data(self):\n",
    "        script_elements = self.soup.find_all(re.compile('script'))\n",
    "        if len(script_elements) > 6:\n",
    "            html_string = str(script_elements[6])\n",
    "            parser = self.MyHTMLParser()\n",
    "            parser.feed(html_string)\n",
    "            self.raw_data = json.loads(json.dumps({\"TheData\": parser.data[0]}))\n",
    "        else:\n",
    "            raise Exception(\"Expected script data not found\")\n",
    "\n",
    "    def extract_reviews_data(self):\n",
    "        if not self.raw_data:\n",
    "            raise Exception(\"Raw data is not available for extraction\")\n",
    "\n",
    "        string_data = self.raw_data[\"TheData\"]\n",
    "\n",
    "        # Extract URLs\n",
    "        user_url_pattern = re.compile(r'https://uk.trustpilot.com/users/[0-9a-z/]*')\n",
    "        user_urls = user_url_pattern.findall(string_data)\n",
    "\n",
    "        # Extract User Names\n",
    "        name_matches = [\n",
    "            match for match in re.finditer(\"name\", string_data)\n",
    "        ]\n",
    "        users = []\n",
    "        for match in name_matches:\n",
    "            snippet = string_data[match.end() + 3:match.end() + 30]\n",
    "            url_match = re.search(\"url\", snippet)\n",
    "            if url_match:\n",
    "                users.append(snippet[:url_match.start() - 3])\n",
    "\n",
    "        # Extract Dates\n",
    "        dates = [\n",
    "            string_data[match.end() + 3:match.end() + 27]\n",
    "            for match in re.finditer(\"datePublished\", string_data)\n",
    "        ]\n",
    "\n",
    "        # Extract Review Bodies\n",
    "        review_bodies = []\n",
    "        for match1, match2 in zip(\n",
    "            re.finditer(\"reviewBody\", string_data),\n",
    "            re.finditer(\"reviewRating\", string_data),\n",
    "        ):\n",
    "            review_bodies.append(string_data[match1.end() + 2:match2.start() - 2])\n",
    "\n",
    "        # Extract Ratings\n",
    "        ratings = [\n",
    "            string_data[match.end() + 3:match.end() + 4]\n",
    "            for match in re.finditer(\"ratingValue\", string_data)\n",
    "        ][1:]\n",
    "\n",
    "        # Extract Website Context\n",
    "        result = self.url.partition(\"https://uk.trustpilot.com/review/\")[2].partition(\"?\")\n",
    "        housing_association_web = pd.Series(result[0]).repeat(len(user_urls))\n",
    "        data_source = pd.Series(self.url).repeat(len(user_urls))\n",
    "\n",
    "        # Create DataFrame\n",
    "        self.reviews_data = pd.DataFrame(\n",
    "            zip(\n",
    "                housing_association_web,\n",
    "                data_source,\n",
    "                users,\n",
    "                user_urls,\n",
    "                dates,\n",
    "                review_bodies,\n",
    "                ratings\n",
    "            ),\n",
    "            columns=[\n",
    "                \"HausingAssociation_web\",\n",
    "                \"DataSource\",\n",
    "                \"User\",\n",
    "                \"UserURL\",\n",
    "                \"DatePublished\",\n",
    "                \"ReviewBody\",\n",
    "                \"RatingValue\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def get_reviews(self):\n",
    "        self.fetch_page()\n",
    "        self.parse_script_data()\n",
    "        self.extract_reviews_data()\n",
    "        return self.reviews_data\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    URL = 'https://uk.trustpilot.com/review/placesforpeople.co.uk'   # YOUR base URL\n",
    "    scraper = TrustpilotReviewScraper(URL)\n",
    "    reviews_df = scraper.get_reviews()\n",
    "    print(reviews_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
