{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in keyword matches for different providers_with MainClassCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def load_data(review_file: str, keyword_file: str):\n",
    "    \"\"\"\n",
    "    Load review and keyword datasets.\n",
    "    \"\"\"\n",
    "    # Load reviews\n",
    "    reviews = pd.read_csv(review_file, header=None, names=['HA', 'Review'])\n",
    "\n",
    "    # Load keywords\n",
    "    keywords = pd.read_excel(keyword_file)\n",
    "\n",
    "    return reviews, keywords\n",
    "\n",
    "def process_keywords(keywords_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create a dictionary of classes and their keywords.\n",
    "    \"\"\"\n",
    "    keywords_dict = {}\n",
    "    for _, row in keywords_df.iterrows():\n",
    "        class_name = row['Class']\n",
    "        keywords = row['Key_words'].split(',')\n",
    "        keywords_dict.setdefault(class_name, []).extend(\n",
    "            [keyword.strip().lower() for keyword in keywords]\n",
    "        )\n",
    "\n",
    "    # Deduplicate keywords per class\n",
    "    keywords_dict = {cls: list(set(kws)) for cls, kws in keywords_dict.items()}\n",
    "\n",
    "    return keywords_dict\n",
    "\n",
    "def vectorize_text(reviews: pd.Series, keywords_dict: dict):\n",
    "    \"\"\"\n",
    "    Vectorize reviews and keywords using TF-IDF.\n",
    "    \"\"\"\n",
    "    keywords_list = []\n",
    "    keyword_classes = []\n",
    "    for cls, kws in keywords_dict.items():\n",
    "        keywords_list.extend(kws)\n",
    "        keyword_classes.extend([cls] * len(kws))\n",
    "\n",
    "    all_texts = keywords_list + reviews.tolist()\n",
    "    vectorizer = TfidfVectorizer(stop_words='english').fit(all_texts)\n",
    "\n",
    "    keywords_tfidf = vectorizer.transform(keywords_list)\n",
    "    reviews_tfidf = vectorizer.transform(reviews)\n",
    "\n",
    "    return keywords_tfidf, reviews_tfidf, keyword_classes\n",
    "\n",
    "def match_keywords(reviews_df: pd.DataFrame, keywords_tfidf, reviews_tfidf, keyword_classes, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Match keywords to reviews and aggregate results by class.\n",
    "    \"\"\"\n",
    "    similarity_scores = cosine_similarity(reviews_tfidf, keywords_tfidf)\n",
    "\n",
    "    aggregated_counts = []\n",
    "    for review_idx, ha_name in enumerate(reviews_df['HA']):\n",
    "        matches = {}\n",
    "        for keyword_idx, score in enumerate(similarity_scores[review_idx]):\n",
    "            if score > threshold:\n",
    "                class_name = keyword_classes[keyword_idx]\n",
    "                matches[class_name] = matches.get(class_name, 0) + 1\n",
    "\n",
    "        for class_name, count in matches.items():\n",
    "            aggregated_counts.append({'HA': ha_name, 'Class': class_name, 'Count': count})\n",
    "\n",
    "    return pd.DataFrame(aggregated_counts)\n",
    "\n",
    "def plot_distribution(distribution: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plot heatmap of keyword distribution.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(distribution, annot=True, cmap='YlGnBu', cbar=True)\n",
    "    plt.title(\"Keyword Distribution by Housing Association\")\n",
    "    plt.xlabel(\"Social Housing Issues (Classes)\")\n",
    "    plt.ylabel(\"Housing Association\")\n",
    "    plt.show()\n",
    "\n",
    "def chi_square_test(distribution: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform Chi-Square test on the distribution.\n",
    "    \"\"\"\n",
    "    contingency_table = distribution.T  # Transpose for correct orientation\n",
    "    chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    print(\"\\nChi-Square Test Result:\")\n",
    "    print(f\"Chi2 Statistic: {chi2}, p-value: {p_value}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"The keyword distributions are significantly different across Housing Associations.\")\n",
    "    else:\n",
    "        print(\"The keyword distributions are not significantly different across Housing Associations.\")\n",
    "\n",
    "def plot_frequency(distribution: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plot frequency distribution as a heatmap.\n",
    "    \"\"\"\n",
    "    frequency_distribution = distribution.div(distribution.sum(axis=1), axis=0)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.heatmap(frequency_distribution, annot=True, cmap='YlGnBu', fmt='.2f', cbar=True)\n",
    "    plt.title(\"Frequency Distribution of Keywords by Housing Association\")\n",
    "    plt.xlabel(\"Social Housing Issues (Classes)\")\n",
    "    plt.ylabel(\"Housing Association\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the analysis pipeline.\n",
    "    \"\"\"\n",
    "    # File paths\n",
    "    review_file = \"YOUR_PATH/file_name1.csv\"\n",
    "    keyword_file = \"YOUR_PATH/file_name2.xlsx\"\n",
    "\n",
    "    # Step 1: Load data\n",
    "    reviews, keywords = load_data(review_file, keyword_file)\n",
    "\n",
    "    # Step 2: Process keywords\n",
    "    keywords_dict = process_keywords(keywords)\n",
    "\n",
    "    # Step 3: Vectorize text\n",
    "    keywords_tfidf, reviews_tfidf, keyword_classes = vectorize_text(reviews['Review'], keywords_dict)\n",
    "\n",
    "    # Step 4: Match keywords to reviews\n",
    "    keyword_counts_df = match_keywords(reviews, keywords_tfidf, reviews_tfidf, keyword_classes)\n",
    "\n",
    "    if keyword_counts_df.empty:\n",
    "        print(\"No keywords found in any review.\")\n",
    "        return\n",
    "\n",
    "    # Step 5: Create and analyze distribution\n",
    "    distribution = keyword_counts_df.pivot_table(\n",
    "        index='HA', columns='Class', values='Count', aggfunc='sum', fill_value=0\n",
    "    )\n",
    "    print(\"Keyword Distribution by Housing Association:\")\n",
    "    print(distribution)\n",
    "\n",
    "    # Plot keyword distribution\n",
    "    plot_distribution(distribution)\n",
    "\n",
    "    # Perform Chi-Square test\n",
    "    chi_square_test(distribution)\n",
    "\n",
    "    # Plot frequency distribution\n",
    "    plot_frequency(distribution)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
